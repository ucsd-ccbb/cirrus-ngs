{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miRNASeq Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The notebook provides steps to run primary analysis of miRNA-Seq data on an existing AWS CFNCluster. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Before running this notebook, ensure:\n",
    "\n",
    "* You are running it on a linux or Mac OSX platform\n",
    "* You have installed the `paramiko` and `scp` packages in the environment where it is running\n",
    "* You have an existing AWS CFN cluster set up, and have the IP address and private key pair file for this cluster\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "## Design File Creation\n",
    "\n",
    "<h4>Analyst note:</h4>\n",
    "This pipeline cannot be run without a project-specific design file created by the analyst.  Create such a file for this project, following the guidance shown below (excerpted from the cirrus-ngs README):\n",
    "\n",
    "The design file is a tab-separated text file that specifies the names of the sequence files to process.  It has no header line.  For miRNA-Seq, it must contain two columns but only the first column is actively used by the pipeline. The **first column** is the filename of the sample (with extensions: e.g. fastq.gz), as shown below in examples modified from the cirrus README:\n",
    ">\n",
    ">For example, a two-column design file for two single-end-sequenced samples named `mysample1` and `mysample2` might look like:\n",
    "\n",
    "```\n",
    "\tmysample1.fastq.gz\t\tnot_applicable\n",
    "\tmysample2.fastq.gz\t\tnot_applicable\n",
    "```\n",
    "\n",
    ">If the sequencing data is paired-end, the first column includes the name of the forward sequencing file, followed by a comma, followed by the name of the reverse sequencing file (note that there must **not** be any spaces between these two file names--only a comma!)  An example two-column design file for two paired-end-sequenced samples named `mysample1` and `mysample2` might look like:\n",
    "\n",
    "```\n",
    "\tmysample1_fwd.fastq.gz,mysample1_rev.fastq.gz\t\tnot_applicable\n",
    "\tmysample2_fwd.fastq.gz,mysample2_rev.fastq.gz\t\tnot_applicable\n",
    "```\n",
    "\n",
    "Note that **second column** must have content but is not actively used by the pipeline, so best practice is to set all values of that column to \"not_applicable\".\n",
    "\n",
    "Once you have created the design file, input its path into the Input Parameters below.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Parameters Set-Up\n",
    "\n",
    "*Project settings*\n",
    "\n",
    "**project_name**: a name for your project, containing no whitespace.\n",
    "\n",
    "**design_file**: the path to your design file for this project. Please see the README for the format specification for the design files. \n",
    "\n",
    "**genome**: the name of the reference genome against which to align during this project; note that currently only \"human\" and \"mouse\" are supported.\n",
    "\n",
    "**s3_input_files_address**: the s3 path to the *directory* in which your input fastq files are found. All fastq files must be in the same s3 bucket.\n",
    "\n",
    "**s3_output_files_address**: the s3 path to the *directory* in which the outputs from your project should be uploaded. This will only be the root directory; please see the README for details of how outputs are structured.\n",
    "\n",
    "*Cluster settings*\n",
    "\n",
    "**your_cluster_name**: the name of your cluster (assigned when it was created using cfncluster). \n",
    "\n",
    "**private_key**: the path to the private key pair file needed to access your cluster.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<h4>Analyst note:</h4>\n",
    "The values in the cell below are example settings, and <strong>MUST</strong> be replaced with appropriate values for your cluster and project.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A project name: no whitespace allowed\n",
    "project_name = \"20190101_testuser_mymirnaseq\"\n",
    "\n",
    "# Path to the design file\n",
    "design_file = \"../../data/cirrus-ngs/mirna_test_design.txt\"\n",
    "\n",
    "# Genome: currently available genomes are human and mouse\n",
    "genome = \"human\"\n",
    "\n",
    "# S3 input and output addresses.\n",
    "# Notice: DO NOT put a forward slash at the end of these s3 addresses.\n",
    "s3_input_files_address = \"s3://path/to/fastq\"\n",
    "s3_output_files_address = \"s3://path/to/output\"\n",
    "    \n",
    "# CFNCluster name\n",
    "your_cluster_name = \"myclustername\"\n",
    "\n",
    "# private key pair file for accessing the new cluster\n",
    "private_key = \"/path/to/your_aws_key.pem\"\n",
    "\n",
    "print(\"Variables set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>Analyst note:</h4>\n",
    "The values shown below are standard settings  and <strong>SHOULD NOT</strong> be modified without a clear understanding of what change should be made and why it is necessary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of cirrus-ngs src directory\n",
    "# on local installation; may be an absolute or relative path.\n",
    "# DO NOT put a forward slash at the end of the path.\n",
    "source_dir_path = \"../../src/cirrus_ngs\"\n",
    "\n",
    "# location to which multqc report should be downloaded\n",
    "import os\n",
    "report_dir = os.getcwd().split(\"notebooks\")[0] + \"data\"\n",
    "\n",
    "# Pipeline name for miRNASeq pipeline;\n",
    "# DO NOT CHANGE\n",
    "pipeline = \"SmallRNASeq\"\n",
    "\n",
    "# Workflow to run; currently this value MUST be \"bowtie2\"\n",
    "# so DO NOT CHANGE\n",
    "workflow = \"bowtie2\"\n",
    "\n",
    "# Analysis steps: a set of strings that contains the analysis steps to run; \n",
    "# note that the order of the steps does not matter.\n",
    "# For miRNASeq, options are \"fastqc\", \"trim\", \"cut_adapt\", \"align_and_count\", and \"multiqc\"\n",
    "analysis_steps = {\"fastqc\", \"trim\", \"cut_adapt\", \"align_and_count\",\"multiqc\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Initiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the CFN cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(source_dir_path)\n",
    "\n",
    "from cfnCluster import CFNClusterManager, ConnectionManager\n",
    "master_ip_address = CFNClusterManager.create_cfn_cluster(cluster_name=your_cluster_name)\n",
    "ssh_client = ConnectionManager.connect_master(hostname=master_ip_address,\n",
    "                                              username=\"ec2-user\",\n",
    "                                              private_key_file=private_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the pipeline on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import DesignFileLoader\n",
    "from util import PipelineManager\n",
    "\n",
    "reference = \"hairpin_{}\".format(genome)\n",
    "print(reference)\n",
    "\n",
    "sample_list, group_list, pair_list = DesignFileLoader.load_design_file(design_file)\n",
    "\n",
    "## DO NOT edit: no user-serviceable settings here\n",
    "PipelineManager.execute(pipeline, ssh_client, project_name, workflow, analysis_steps, s3_input_files_address,\n",
    "                       sample_list, group_list, s3_output_files_address, reference, \"NA\", pair_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Status Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the pipeline is running, it will not push information on its status to this notebook.  However, it is possible to pull information about the status of the pipeline at any time using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status check settings:\n",
    "\n",
    "# Specify a step (one that is in the analysis_steps set) to check on the status of \n",
    "# or set to \"all\" to see the status of all steps\n",
    "step=\"all\"\n",
    "\n",
    "# View verbose status information by setting this value to True or \n",
    "# view abbreviated status information by setting it to False\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "PipelineManager.check_status(ssh_client, step, pipeline, workflow, project_name, analysis_steps,verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failure Handling\n",
    "If the status information above indicates that steps have failed, examine the log files accessible from the cluster's master node to identify the issue.  To do this, gather the login information for the master node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(private_key)\n",
    "# print(master_ip_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, `ssh` into the master node with a command of the following form:\n",
    "    \n",
    "    ssh -i <private_key> ec2-user@<master_ip_address>\n",
    "    \n",
    "Logs are stored in the `/shared/workspace/logs/` directory, under sub-folders for the pipeline, workflow, and project name.  `cd` to this directory with a command of the following form:\n",
    "\n",
    "    cd /shared/workspace/logs/SmallRNASeq/bowtie2/<project_name>\n",
    "    \n",
    "    \n",
    "If a sample's log files are empty, this indicates that it was not downloaded from s3 (because by default the aws s3 command download runs in quiet mode and does not generate log messages even on failure).  Double-check the file names in the design file to ensure they are correct and that the files are actually in the stated s3 location.\n",
    "\n",
    "Once the cause of the failures has been addressed, simply resubmit the jobs without clearing the logs or outputs; cirrus-ngs will automatically rerun the failed samples, while the samples which have outputs wonâ€™t be run again.  If it is necessary to redo the entire run from scratch, delete both the project folder in the logs and also the outputs before commencing the rerun to ensure that all existing state has been cleared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MultiQC Report Display\n",
    "\n",
    "If the multiqc step has been **run and completed**, the code below can be used to view the multiqc report to assess the overall outcome of the primary analysis.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "        \n",
    "**NOTE** that report display will only work if the `aws` command line tool has been configured with AWS credentials in the environment in which the notebook is being executed by first running the `aws configure` command; if it has not, a `fatal error: Unable to locate credentials` message will be displayed.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the multiqc html file to local directory\n",
    "!aws s3 cp $s3_output_files_address/$project_name/$workflow/multiqc_report.html $report_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(os.path.relpath(\"{}/multiqc_report.html\".format(report_dir)), width=\"100%\", height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Methods Documentation\n",
    "\n",
    "Print out the settings and script for each step run in the pipeline and workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from util import AddonsManager\n",
    "AddonsManager.display_pipeline_workflow_settings_and_scripts(ssh_client, pipeline, workflow, analysis_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the software configuration file, including software and reference genome versions, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AddonsManager.display_software_config(ssh_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
