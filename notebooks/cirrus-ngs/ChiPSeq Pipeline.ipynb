{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChIP-Seq Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be sure to install paramiko and scp with pip before using this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure AWS key pair, data location on S3 and the project information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell only contains information that you, the user, should input.\n",
    "\n",
    "#### String Fields\n",
    "\n",
    "**s3_input_files_address**: This is an s3 path to where your input fastq files are found. This shouldn't be the path to the actual fastq files, just to the directory containing all of them. All fastq files must be in the same s3 bucket.\n",
    "\n",
    "**s3_output_files_address**: This is an s3 path to where you would like the outputs from your project to be uploaded. This will only be the root directory, please see the README for information about exactly how outputs are structured\n",
    "\n",
    "**design_file**: This is a path to your design file for this project. Please see the README for the format specification for the design files. \n",
    "\n",
    "**your_cluster_name**: This is the name given to your cluster when it was created using ParallelCluster. \n",
    "\n",
    "**private_key**: The path to your private key needed to access your cluster.\n",
    "\n",
    "**project_name**: Name of your project. There should be no whitespace.\n",
    "\n",
    "**workflow**: The workflow you want to run for this project. For the ChIPSeq pipeline the only possible workflow is \"homer\".\n",
    "\n",
    "**genome**: The name of the reference you want to use for your project. Currently only \"hg19\" and \"mm10\" are supported here.\n",
    "\n",
    "**style**: This will always be either \"factor\" or \"histone\" depending on your purposes. The \"factor\" style is more fitting for transcription factor analysis while the \"histone\" style is intended for histone analysis. More details can be found [here](http://homer.ucsd.edu/homer/ngs/peaks.html)\n",
    "\n",
    "#### analysis_steps\n",
    "This is a set of strings that contains the steps you would like to run. The order of the steps does not matter.\n",
    "\n",
    "posible homer steps: \"fastqc\", \"trim\", \"align\", \"multiqc\", \"make_tag_directory\", \"make_UCSC_file\", \"find_peaks\", \"annotate_peaks\", \"pos2bed\", \"find_motifs_genome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../src/cirrus_ngs\")\n",
    "from awsCluster import ClusterManager, ConnectionManager\n",
    "from util import PipelineManager\n",
    "from util import DesignFileLoader\n",
    "from util import ConfigParser\n",
    "\n",
    "#s3 addresses for input files and output files\n",
    "s3_input_files_address = \"s3://path/to/fastq\"\n",
    "s3_output_files_address = \"s3://path/to/output\"\n",
    "\n",
    "## Path to the design file\n",
    "design_file = \"../../data/cirrus-ngs/chipseq_design_example.txt\"\n",
    "\n",
    "## ParallelCluster name\n",
    "your_cluster_name = \"clustername\"\n",
    "\n",
    "## The private key pair for accessing cluster.\n",
    "private_key = \"/path/to/your_aws_key.pem\"\n",
    "\n",
    "## Project information\n",
    "project_name = \"test_project\"\n",
    "\n",
    "#options: homer\n",
    "workflow = \"homer\"\n",
    "\n",
    "#options: hg38, hg19, mm10\n",
    "genome = \"hg19\"\n",
    "\n",
    "#options: factor, histone\n",
    "style = \"histone\"\n",
    "\n",
    "##order does not matter\n",
    "\n",
    "##can be fastqc, trim, bowtie, multiqc, make_tag_directory, make_UCSC_file, \n",
    "#find_peaks, annotate_peaks, pos2bed, find_motifs_genome\n",
    "analysis_steps = {\n",
    "                    \"fastqc\"\n",
    "                    ,\"trim\"\n",
    "                    ,\"align\"\n",
    "                    ,\"multiqc\"\n",
    "                    ,\"make_tag_directory\"\n",
    "                    ,\"make_UCSC_file\"\n",
    "                    ,\"find_peaks\"\n",
    "                    ,\"annotate_peaks\"\n",
    "                    ,\"pos2bed\"\n",
    "                    ,\"find_motifs_genome\"\n",
    "                }\n",
    "\n",
    "\n",
    "print(\"variables set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create ParallelCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cell connects to your cluster. Run before step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_ip_address = ClusterManager.create_aws_cluster(cluster_name=your_cluster_name)\n",
    "ssh_client = ConnectionManager.connect_master(hostname=master_ip_address,\n",
    "               username=\"ec2-user\",\n",
    "               private_key_file=private_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell actually executes your pipeline. Make sure that steps 1 and 2 have been completed before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Primary analysis details\n",
      "#Author: Guorong Xu\n",
      "#Date: 2019-07-25 14:06:40\n",
      "\n",
      "#Reference used:\n",
      "Reference genome: ucsc.hg19.fasta\n",
      "Annotation: gencode.v19.annotation.gtf\n",
      "\n",
      "#Tools used:\n",
      "FASTQC: 0.11.3\n",
      "Trimmomatic: 0.36\n",
      "samtools: 1.9\n",
      "MultiQC: v1.3\n",
      "bowtie: 1.0.1\n",
      "homer: 4.8.3\n",
      "\n",
      "\n",
      "\n",
      "{'trim', 'make_tag_directory', 'align', 'find_peaks', 'annotate_peaks', 'find_motifs_genome', 'multiqc', 'make_UCSC_file', 'fastqc', 'pos2bed'}\n"
     ]
    }
   ],
   "source": [
    "## DO NOT EDIT BELOW\n",
    "## print the analysis information\n",
    "reference_list, tool_list = ConfigParser.parse(os.getcwd())\n",
    "ConfigParser.print_software_info(\"ChiPSeq\", workflow, genome, reference_list, tool_list)\n",
    "\n",
    "print (analysis_steps)\n",
    "\n",
    "sample_list, group_list, pairs_list = DesignFileLoader.load_design_file(design_file)\n",
    "\n",
    "PipelineManager.execute(\"ChiPSeq\", ssh_client, project_name, workflow, analysis_steps, s3_input_files_address,\n",
    "                       sample_list, group_list, s3_output_files_address, genome, style, pairs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check status of pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you to check the status of your pipeline. You can specify a step or set the step variable to \"all\". If you specify a step it should be one that is in your analysis_steps set. You can toggle how verbose the status checking is by setting the verbose flag (at the end of the second line) to False. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking status of jobs...\n",
      "\n",
      "Your project will go through the following steps:\n",
      "\tfastqc, trim, align, make_tag_directory, make_UCSC_file, find_peaks, annotate_peaks, pos2bed, find_motifs_genome\n",
      "\n",
      "The fastqc step calls the fastqc.sh script on the cluster\n",
      "The fastqc step has finished running without failure\n",
      "\n",
      "The trim step calls the trim.sh script on the cluster\n",
      "The trim step has finished running without failure\n",
      "\n",
      "The align step calls the bowtie.sh script on the cluster\n",
      "The align step has finished running without failure\n",
      "\n",
      "The make_tag_directory step calls the make_tag_directory.sh script on the cluster\n",
      "The make_tag_directory step has finished running without failure\n",
      "\n",
      "The make_UCSC_file step calls the make_UCSC_file.sh script on the cluster\n",
      "The make_UCSC_file step has finished running without failure\n",
      "\n",
      "The find_peaks step calls the findpeaks.sh script on the cluster\n",
      "The find_peaks step has finished running without failure\n",
      "\n",
      "The annotate_peaks step calls the annotate_peaks.sh script on the cluster\n",
      "The annotate_peaks step has finished running without failure\n",
      "\n",
      "The pos2bed step calls the pos2bed.sh script on the cluster\n",
      "The pos2bed step has finished running without failure\n",
      "\n",
      "The find_motifs_genome step calls the find_motifs_genome.sh script on the cluster\n",
      "The find_motifs_genome step has finished running without failure\n",
      "\n",
      "\n",
      "Your pipeline has finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = \"all\" #can be any step in analysis_steps or \"all\"\n",
    "PipelineManager.check_status(ssh_client, step, \"ChiPSeq\", workflow, project_name, analysis_steps,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your pipeline is finished run this cell just in case there's some processes still running.\n",
    "This is only relevant if you plan on doing another run on the same cluster afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PipelineManager.stop_pipeline(ssh_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display MultiQC report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Run the cells below after the multiqc step is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the multiqc html file to local\n",
    "notebook_dir = os.getcwd().split(\"notebooks\")[0] + \"data/\"\n",
    "!aws s3 cp $s3_output_files_address/$project_name/$workflow/multiqc_report.html $notebook_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(os.path.relpath(\"{}multiqc_report.html\".format(notebook_dir)), width=\"100%\", height=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
