{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <strong>Analyst Note:</strong><br />\n",
    "    Fill in the human-readable name of your project and the type of your data, such as:\n",
    "    \n",
    "   > # Dr. Doe Human Patient Time-Series RNASeq\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "# Primary Analysis\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <strong>Analyst Note:</strong><br />\n",
    "    Fill in the author attributions for your analysis, such as:\n",
    "    \n",
    "   > * Guorong Xu, CCBB (g1xu@ucsd.edu)\n",
    "</div>\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "* [Background](#Background)\n",
    "* [Introduction](#Introduction)\n",
    "* [Design File Creation](#Design-File-Creation)\n",
    "* [Parameters Input](#Parameters_Input)\n",
    "* [Pipeline Initiation](#Pipeline-Initiation)\n",
    "* [Pipeline Status Checking](#Pipeline-Status-Checking)\n",
    "* [MultiQC Report Display](#MultiQC-Report-Display)\n",
    "* [Archiving](#Archiving)\n",
    "* [Appendix: Methods Documentation](#Appendix:-Methods-Documentation)\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <strong>Analyst Note:</strong><br />\n",
    "    Fill in background on the specific project here, such as \n",
    "   \n",
    "   > The fastq data analyzed in this notebook were downloaded the ftp://igm-storage1.ucsd.edu/190319_K00180_0772_AH2Y27BBXY_SR75_Combo/ link provided by Dr. Postdoc on 03/20/2019.\n",
    "   \n",
    "</div>\n",
    "\n",
    "[Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The notebook provides steps to run primary analysis of either RNASeq or miRNASeq data on an existing AWS CFNCluster. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Before running this notebook, ensure:\n",
    "\n",
    "* You are running it on a linux or Mac OSX platform\n",
    "* You have installed the `paramiko` and `scp` packages in the environment where it is running\n",
    "* You have an existing AWS CFN cluster set up, and have the IP address and private key pair file for this cluster\n",
    "* The master node of the cluster must be running (not stopped) on AWS\n",
    "\n",
    "</div>\n",
    "\n",
    "[Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "## Design File Creation\n",
    "\n",
    "<h4>Analyst note:</h4>\n",
    "This pipeline cannot be run without a project-specific design file created by the analyst.  Create such a file for this project, following the guidance shown below (excerpted from the cirrus-ngs README):\n",
    "\n",
    "The design file is a tab-separated text file that specifies the names of the sequence files to process.  It has no header line.  For RNASeq and miRNA-Seq, it must contain two columns but only the first column is actively used by the pipeline. The **first column** is the filename of the sample (with extensions: e.g. fastq.gz), as shown below in examples modified from the cirrus README:\n",
    ">\n",
    ">For example, a two-column design file for two single-end-sequenced samples named `mysample1` and `mysample2` might look like:\n",
    "\n",
    "```\n",
    "\tmysample1.fastq.gz\t\tnot_applicable\n",
    "\tmysample2.fastq.gz\t\tnot_applicable\n",
    "```\n",
    "\n",
    ">If the sequencing data is paired-end, the first column includes the name of the forward sequencing file, followed by a comma, followed by the name of the reverse sequencing file (note that there must **not** be any spaces between these two file names--only a comma!)  An example two-column design file for two paired-end-sequenced samples named `mysample1` and `mysample2` might look like:\n",
    "\n",
    "```\n",
    "\tmysample1_fwd.fastq.gz,mysample1_rev.fastq.gz\t\tnot_applicable\n",
    "\tmysample2_fwd.fastq.gz,mysample2_rev.fastq.gz\t\tnot_applicable\n",
    "```\n",
    "\n",
    "Note that **second column** must have content but is not actively used by the pipeline, so best practice is to set all values of that column to \"not_applicable\".\n",
    "\n",
    "Once you have created the design file, input its path into the Input Parameters below.\n",
    "\n",
    "</div>\n",
    "\n",
    "[Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Input\n",
    "\n",
    "*Project settings*\n",
    "\n",
    "**project_name**: a name for your project, containing no whitespace.\n",
    "\n",
    "**design_file**: the path to your design file for this project. Please see the README for the format specification for the design files. \n",
    "\n",
    "**genome**: the name of the reference genome against which to align during this project; note that currently only \"human\" and \"mouse\" are supported.\n",
    "\n",
    "**s3_input_files_address**: the s3 path to the *directory* in which your input fastq files are found. All fastq files must be in the same s3 bucket.\n",
    "\n",
    "**s3_output_files_address**: the s3 path to the *directory* in which the outputs from your project should be uploaded. This will only be the root directory; please see the README for details of how outputs are structured.\n",
    "\n",
    "*Cluster settings*\n",
    "\n",
    "**your_cluster_name**: the name of your cluster (assigned when it was created using cfncluster). \n",
    "\n",
    "**private_key**: the path to the private key pair file needed to access your cluster.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<h4>Analyst note:</h4>\n",
    "The values in the cell below are example settings, and <strong>MUST</strong> be replaced with appropriate values for your cluster and project.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A project name: no whitespace allowed\n",
    "project_name = \"20190101_testuser_mymirnaseq\"\n",
    "\n",
    "# Path to the design file\n",
    "design_file = \"../../data/cirrus-ngs/mirna_test_design.txt\"\n",
    "\n",
    "# Pipeline: choose either \"SmallRNASeq\" (for miRNASeq) or \"RNASeq\"\n",
    "pipeline = \"SmallRNASeq\"\n",
    "\n",
    "# IF you chose \"RNASeq\" as the pipeline above, \n",
    "# then set the genome to hg19 for human or mm10 for mouse\n",
    "#(mm10 only supported in star_rsem as of now).\n",
    "# Conversely, if you chose \"SmallRNASeq\" as the pipeline above,\n",
    "# then set the genome to \"human\" for human or \"mouse\" for mouse.\n",
    "# Note that ONLY human and mouse are supported.\n",
    "genome = \"mm10\"\n",
    "\n",
    "# If and only if you chose \"RNASeq\" as the pipeline above, \n",
    "# then set the workflow value below to one of these three \n",
    "# choices: \"star_gatk\", \"star_htseq\", or \"star_rsem\".\n",
    "# If you chose \"SmallRNASeq\" as the pipeline above,\n",
    "# simply leave the workflow as None\n",
    "workflow = None\n",
    "\n",
    "# S3 input, output, and archive addresses.\n",
    "# Notice: DO NOT put a forward slash at the end of these s3 addresses.\n",
    "s3_input_files_address = \"s3://path/to/fastq\"\n",
    "s3_output_files_address = \"s3://path/to/output\"\n",
    "s3_archive_files_address = \"s3://path/to/archive\"\n",
    "\n",
    "# CFNCluster name\n",
    "your_cluster_name = \"myclustername\"\n",
    "\n",
    "# private key pair file for accessing the new cluster\n",
    "private_key = \"/path/to/your_aws_key.pem\"\n",
    "\n",
    "print(\"Variables set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h4>Analyst note:</h4>\n",
    "The values shown below are standard settings  and <strong>SHOULD NOT</strong> be modified without a clear understanding of what change should be made and why it is necessary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of cirrus-ngs src directory\n",
    "# on local installation; may be an absolute or relative path.\n",
    "# DO NOT put a forward slash at the end of the path.\n",
    "source_dir_path = \"../../src/cirrus_ngs\"\n",
    "\n",
    "# location to which multqc report should be downloaded\n",
    "import os\n",
    "report_dir = os.getcwd().split(\"notebooks\")[0] + \"data\"\n",
    "\n",
    "# Analysis steps: a set of strings that contains the analysis steps to run. \n",
    "# note that the order of the analysis steps does not matter; \n",
    "# the analysis_steps variable only specifies WHICH steps to run,\n",
    "# and the pipeline/workflow itself specifies the order in which\n",
    "# the chosen steps are run.\n",
    "# IF AND ONLY IF you are a power user who wants to run/rerun just\n",
    "# a subset of steps, then input the steps you want in the analysis_steps \n",
    "# variable below.  If you are a normal user who wants to run the full \n",
    "# pipeline, leave it as None.\n",
    "analysis_steps = None\n",
    "\n",
    "if pipeline == \"SmallRNASeq\":\n",
    "    # SmallRNASeq has only one approved workflow, so \n",
    "    # if that is the pipeline, set the workflow to the \n",
    "    # only approved one;\n",
    "    workflow = \"bowtie2\"\n",
    "    reference = \"hairpin_{}\".format(genome)\n",
    "    full_analysis_steps = {\"fastqc\", \"trim\", \"cut_adapt\", \"align_and_count\",\"merge_counts\",\"multiqc\"}\n",
    "elif pipeline == \"RNASeq\":\n",
    "    reference = genome\n",
    "    if workflow == \"star_gatk\":\n",
    "        full_analysis_steps = {\"fastqc\", \"trim\", \"align\", \"multiqc\", \"variant_calling\"}\n",
    "    elif workflow == \"star_htseq\":\n",
    "        full_analysis_steps = {\"fastqc\", \"trim\", \"align\", \"multiqc\", \"count\", \"merge_counts\"}\n",
    "    elif workflow == \"star_rsem\":\n",
    "        full_analysis_steps = {\"fastqc\", \"trim\", \"align_count\", \"multiqc\", \"merge_counts\"}\n",
    "analysis_steps = full_analysis_steps if analysis_steps is None else analysis_steps\n",
    "\n",
    "# if analysis steps is STILL none after the code above, \n",
    "# then the pipeline workflow combination is unrecognized, so throw an error:\n",
    "if analysis_steps is None:\n",
    "    raise ValueError(\"Unrecognized pipeline/workflow combination: {0}/{1}\".format(pipeline, workflow))\n",
    "\n",
    "print(\"workflow: {0}\".format(workflow))\n",
    "print(\"reference: {0}\".format(reference))\n",
    "print(\"analysis_steps (not necessarily in run order): {0}\".format(analysis_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#Table-of-Contents)\n",
    "\n",
    "## Pipeline Initiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the CFN cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(source_dir_path)\n",
    "\n",
    "from cfnCluster import CFNClusterManager, ConnectionManager\n",
    "master_ip_address = CFNClusterManager.create_cfn_cluster(cluster_name=your_cluster_name)\n",
    "ssh_client = ConnectionManager.connect_master(hostname=master_ip_address,\n",
    "                                              username=\"ec2-user\",\n",
    "                                              private_key_file=private_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the pipeline on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT edit: no user-serviceable settings here\n",
    "from util import DesignFileLoader\n",
    "from util import PipelineManager\n",
    "\n",
    "sample_list, group_list, pair_list = DesignFileLoader.load_design_file(design_file)\n",
    "PipelineManager.execute(pipeline, ssh_client, project_name, workflow, analysis_steps, s3_input_files_address,\n",
    "                       sample_list, group_list, s3_output_files_address, reference, \"NA\", pair_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#Table-of-Contents)\n",
    "\n",
    "## Pipeline Status Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the pipeline is running, it will not push information on its status to this notebook.  However, it is possible to pull information about the status of the pipeline at any time using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status check settings:\n",
    "\n",
    "# Specify a step (one that is in the analysis_steps set) to check on the status of \n",
    "# or set to \"all\" to see the status of all steps\n",
    "step=\"all\"\n",
    "\n",
    "# View verbose status information by setting this value to True or \n",
    "# view abbreviated status information by setting it to False\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Be aware that the below cell that reports analysis status can take a very long time (10s of minutes) to complete if there are large numbers of jobs running on the cluster for the analysis.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "PipelineManager.check_status(ssh_client, step, pipeline, workflow, project_name, analysis_steps,verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failure Handling\n",
    "If the status information above indicates that steps have failed, examine the log files accessible from the cluster's master node to identify the issue.  To do this, gather the login information for the master node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(private_key)\n",
    "# print(master_ip_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, `ssh` into the master node with a command of the following form:\n",
    "    \n",
    "    ssh -i <private_key> ec2-user@<master_ip_address>\n",
    "    \n",
    "Logs are stored in the `/shared/workspace/logs/` directory, under sub-folders for the pipeline, workflow, and project name.  `cd` to this directory with a command of the following form:\n",
    "\n",
    "    cd /shared/workspace/logs/SmallRNASeq/bowtie2/<project_name>\n",
    "    \n",
    "    \n",
    "If a sample's log files are empty, this indicates that it was not downloaded from s3 (because by default the aws s3 command download runs in quiet mode and does not generate log messages even on failure).  Double-check the file names in the design file to ensure they are correct and that the files are actually in the stated s3 location.\n",
    "\n",
    "Once the cause of the failures has been addressed, simply resubmit the jobs without clearing the logs or outputs; cirrus-ngs will automatically rerun the failed samples, while the samples which have outputs won’t be run again.  If it is necessary to redo the entire run from scratch, delete both the project folder in the logs and also the outputs before commencing the rerun to ensure that all existing state has been cleared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Table of Contents](#Table-of-Contents)\n",
    "\n",
    "## MultiQC Report Display\n",
    "\n",
    "If the multiqc step has been **run and completed**, the code below can be used to view the multiqc report to assess the overall outcome of the primary analysis.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "        \n",
    "**NOTE** that report display will only work if the `aws` command line tool has been configured with AWS credentials in the environment in which the notebook is being executed by first running the `aws configure` command; if it has not, a `fatal error: Unable to locate credentials` message will be displayed.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the multiqc html file to local directory\n",
    "!aws s3 cp $s3_output_files_address/$project_name/$workflow/multiqc_report.html $report_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(os.path.relpath(\"{}/multiqc_report.html\".format(report_dir)), width=\"100%\", height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#Table-of-Contents)\n",
    "\n",
    "## Archiving\n",
    "\n",
    "Generally the outputs are written to a temporary directory on S3 until the analysis run has been verified as successful.  The final step is therefore to move the outputs of a successful run to their permanent archive location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# get today's date, without hyphens between yr/mo/day\n",
    "curr_date = str(datetime.datetime.now().date()).replace(\"-\",\"\")\n",
    "archive_subdir_name = \"{0}_{1}_primary_analysis_deliverable\".format(curr_date, workflow)\n",
    "print(archive_subdir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 mv $s3_output_files_address/$project_name/$workflow/ $s3_archive_files_address/$archive_subdir_name/outputs --recursive --exclude \"*.fastq\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If desired, delete the output directory that was used to temporarily store the outputs before archiving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 rm --recursive $s3_output_files_address/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#Table-of-Contents)\n",
    "\n",
    "## Appendix: Methods Documentation\n",
    "\n",
    "Print out the settings and script for each step run in the pipeline and workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from util import AddonsManager\n",
    "AddonsManager.display_pipeline_workflow_settings_and_scripts(ssh_client, pipeline, workflow, analysis_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the software configuration file, including software and reference genome versions, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AddonsManager.display_software_config(ssh_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Copyright (c) 2018 UC San Diego Center for Computational Biology & Bioinformatics under the MIT License\n",
    "\n",
    "Notebook template by Guorong Xu and Amanda Birmingham"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
